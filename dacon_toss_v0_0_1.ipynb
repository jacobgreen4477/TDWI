{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacobgreen4477/TDWI/blob/master/dacon_toss_v0_0_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> title : 토스 NEXT ML CHALLENGE : 광고 클릭 예측(CTR) 모델 개발 <br>\n",
        "> author : hjy <br>"
      ],
      "metadata": {
        "id": "9wCwh1_w7bw5"
      },
      "id": "9wCwh1_w7bw5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### libarary"
      ],
      "metadata": {
        "id": "uLbG6byT7o1o"
      },
      "id": "uLbG6byT7o1o"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, random\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "7M7yQyic7RgF"
      },
      "id": "7M7yQyic7RgF",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CFG = {\n",
        "    'BATCH_SIZE': 1024,\n",
        "    'EPOCHS': 5,\n",
        "    'LEARNING_RATE': 1e-3,\n",
        "    'SEED': 42\n",
        "}\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(CFG['SEED'])\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnV3gAzm8DnB",
        "outputId": "403fb3fa-732e-46b9-877a-b88d7322d2eb"
      },
      "id": "mnV3gAzm8DnB",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ClickDataset(Dataset):\n",
        "    def __init__(self, df, num_cols, cat_cols, seq_col, target_col=None, has_target=True):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.num_cols = num_cols\n",
        "        self.cat_cols = cat_cols\n",
        "        self.seq_col = seq_col\n",
        "        self.target_col = target_col\n",
        "        self.has_target = has_target\n",
        "        self.num_X = self.df[self.num_cols].astype(float).fillna(0).values\n",
        "        self.cat_X = self.df[self.cat_cols].astype(int).values\n",
        "        self.seq_strings = self.df[self.seq_col].astype(str).values\n",
        "        if self.has_target:\n",
        "            self.y = self.df[self.target_col].astype(np.float32).values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        num_x = torch.tensor(self.num_X[idx], dtype=torch.float)\n",
        "        cat_x = torch.tensor(self.cat_X[idx], dtype=torch.long)\n",
        "        s = self.seq_strings[idx]\n",
        "        if s:\n",
        "            arr = np.fromstring(s, sep=\",\", dtype=np.float32)\n",
        "        else:\n",
        "            arr = np.array([0.0], dtype=np.float32)\n",
        "        seq = torch.from_numpy(arr)\n",
        "        if self.has_target:\n",
        "            y = torch.tensor(self.y[idx], dtype=torch.float)\n",
        "            return num_x, cat_x, seq, y\n",
        "        else:\n",
        "            return num_x, cat_x, seq\n",
        "\n",
        "def collate_fn_train(batch):\n",
        "    num_x, cat_x, seqs, ys = zip(*batch)\n",
        "    num_x = torch.stack(num_x)\n",
        "    cat_x = torch.stack(cat_x)\n",
        "    ys = torch.stack(ys)\n",
        "    seqs_padded = nn.utils.rnn.pad_sequence(seqs, batch_first=True, padding_value=0.0)\n",
        "    seq_lengths = torch.tensor([len(s) for s in seqs], dtype=torch.long)\n",
        "    seq_lengths = torch.clamp(seq_lengths, min=1)\n",
        "    return num_x, cat_x, seqs_padded, seq_lengths, ys\n",
        "\n",
        "def collate_fn_infer(batch):\n",
        "    num_x, cat_x, seqs = zip(*batch)\n",
        "    num_x = torch.stack(num_x)\n",
        "    cat_x = torch.stack(cat_x)\n",
        "    seqs_padded = nn.utils.rnn.pad_sequence(seqs, batch_first=True, padding_value=0.0)\n",
        "    seq_lengths = torch.tensor([len(s) for s in seqs], dtype=torch.long)\n",
        "    seq_lengths = torch.clamp(seq_lengths, min=1)\n",
        "    return num_x, cat_x, seqs_padded, seq_lengths\n",
        "\n",
        "class CrossNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, num_layers=2):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([\n",
        "            nn.Linear(input_dim, 1, bias=True) for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x0):\n",
        "        x = x0\n",
        "        for w in self.layers:\n",
        "            x = x0 * w(x) + x\n",
        "        return x\n",
        "\n",
        "class WideDeepCTR(nn.Module):\n",
        "    def __init__(self, num_features, cat_cardinalities, emb_dim=16, lstm_hidden=64,\n",
        "                 hidden_units=[512,256,128], dropout=[0.1,0.2,0.3]):\n",
        "        super().__init__()\n",
        "        self.emb_layers = nn.ModuleList([\n",
        "            nn.Embedding(cardinality, emb_dim) for cardinality in cat_cardinalities\n",
        "        ])\n",
        "        cat_input_dim = emb_dim * len(cat_cardinalities)\n",
        "        self.bn_num = nn.BatchNorm1d(num_features)\n",
        "        self.lstm = nn.LSTM(input_size=1, hidden_size=lstm_hidden,\n",
        "                            num_layers=2, batch_first=True, bidirectional=True)\n",
        "        seq_out_dim = lstm_hidden * 2\n",
        "        self.cross = CrossNetwork(num_features + cat_input_dim + seq_out_dim, num_layers=2)\n",
        "        input_dim = num_features + cat_input_dim + seq_out_dim\n",
        "        layers = []\n",
        "        for i, h in enumerate(hidden_units):\n",
        "            layers += [nn.Linear(input_dim, h), nn.ReLU(), nn.Dropout(dropout[i % len(dropout)])]\n",
        "            input_dim = h\n",
        "        layers += [nn.Linear(input_dim, 1)]\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, num_x, cat_x, seqs, seq_lengths):\n",
        "        num_x = self.bn_num(num_x)\n",
        "        cat_embs = [emb(cat_x[:, i]) for i, emb in enumerate(self.emb_layers)]\n",
        "        cat_feat = torch.cat(cat_embs, dim=1)\n",
        "        seqs = seqs.unsqueeze(-1)\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(seqs, seq_lengths.cpu(),\n",
        "                                                   batch_first=True, enforce_sorted=False)\n",
        "        _, (h_n, _) = self.lstm(packed)\n",
        "        h = torch.cat([h_n[-2], h_n[-1]], dim=1)\n",
        "        z = torch.cat([num_x, cat_feat, h], dim=1)\n",
        "        z_cross = self.cross(z)\n",
        "        out = self.mlp(z_cross)\n",
        "        return out.squeeze(1)\n",
        "\n",
        "def train_model(train_df, num_cols, cat_cols, seq_col, target_col, batch_size, epochs, lr, device):\n",
        "    train_dataset = ClickDataset(train_df, num_cols, cat_cols, seq_col, target_col, True)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
        "                              collate_fn=collate_fn_train, pin_memory=True)\n",
        "    cat_cardinalities = [len(cat_encoders[c].classes_) for c in cat_cols]\n",
        "    model = WideDeepCTR(\n",
        "        num_features=len(num_cols),\n",
        "        cat_cardinalities=cat_cardinalities,\n",
        "        emb_dim=16,\n",
        "        lstm_hidden=64,\n",
        "        hidden_units=[512,256,128],\n",
        "        dropout=[0.1,0.2,0.3]\n",
        "    ).to(device)\n",
        "    pos_weight_value = (len(train_df) - train_df[target_col].sum()) / train_df[target_col].sum()\n",
        "    pos_weight = torch.tensor([pos_weight_value], dtype=torch.float).to(device)\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=2, T_mult=2)\n",
        "    print(\"학습 시작\")\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for num_x, cat_x, seqs, lens, ys in tqdm(train_loader, desc=f\"[Train Epoch {epoch}]\"):\n",
        "            num_x, cat_x, seqs, lens, ys = num_x.to(device), cat_x.to(device), seqs.to(device), lens.to(device), ys.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(num_x, cat_x, seqs, lens)\n",
        "            loss = criterion(logits, ys)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            total_loss += loss.item() * ys.size(0)\n",
        "        total_loss /= len(train_dataset)\n",
        "        print(f\"[Epoch {epoch}] Train Loss: {total_loss:.4f}\")\n",
        "        if torch.cuda.is_available():\n",
        "            print(f\"[DEBUG] GPU Allocated: {torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n",
        "    print(\"학습 완료\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "NnIigL7Z8DqA"
      },
      "id": "NnIigL7Z8DqA",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_categoricals(train_df, test_df, cat_cols):\n",
        "    encoders = {}\n",
        "    for col in cat_cols:\n",
        "        le = LabelEncoder()\n",
        "        all_values = pd.concat([train_df[col], test_df[col]], axis=0).astype(str).fillna(\"UNK\")\n",
        "        le.fit(all_values)\n",
        "        train_df[col] = le.transform(train_df[col].astype(str).fillna(\"UNK\"))\n",
        "        test_df[col]  = le.transform(test_df[col].astype(str).fillna(\"UNK\"))\n",
        "        encoders[col] = le\n",
        "        print(f\"{col} unique categories: {len(le.classes_)}\")\n",
        "    return train_df, test_df, encoders"
      ],
      "metadata": {
        "id": "PlWzhARx8eBQ"
      },
      "id": "PlWzhARx8eBQ",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GCD883kf8xnZ"
      },
      "id": "GCD883kf8xnZ",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SJNdAjHk8xqn"
      },
      "id": "SJNdAjHk8xqn",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kxlFoWEv8Ds9"
      },
      "id": "kxlFoWEv8Ds9",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### read data"
      ],
      "metadata": {
        "id": "-AxKNk1q8EFA"
      },
      "id": "-AxKNk1q8EFA"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDRl9NS27Riw",
        "outputId": "7a496366-5e87-4f59-d33b-badeecbe23ad"
      },
      "id": "xDRl9NS27Riw",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "print(\"데이터 로드 시작\")\n",
        "train = pd.read_parquet(\"/content/drive/MyDrive/toss/train.parquet\", engine=\"pyarrow\")\n",
        "test = pd.read_parquet(\"/content/drive/MyDrive/toss/test.parquet\", engine=\"pyarrow\")\n",
        "print(f\"Train shape: {train.shape}\")\n",
        "print(f\"Test shape: {test.shape}\")\n",
        "print(\"데이터 로드 완료\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAW52QUZ7RmP",
        "outputId": "e68dd9f3-bece-495a-b7b7-8bd1dcfe9ad8"
      },
      "id": "zAW52QUZ7RmP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 로드 시작\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CKrO_6xN80HJ"
      },
      "id": "CKrO_6xN80HJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wyc0CWhg80J2"
      },
      "id": "wyc0CWhg80J2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yNs5tLWR80NA"
      },
      "id": "yNs5tLWR80NA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### encoding"
      ],
      "metadata": {
        "id": "Uyosw8mC80ns"
      },
      "id": "Uyosw8mC80ns"
    },
    {
      "cell_type": "code",
      "source": [
        "target_col = \"clicked\"\n",
        "seq_col = \"seq\"\n",
        "FEATURE_EXCLUDE = {target_col, seq_col, \"ID\"}\n",
        "feature_cols = [c for c in train.columns if c not in FEATURE_EXCLUDE]\n",
        "\n",
        "cat_cols = [\"gender\", \"age_group\", \"inventory_id\", \"l_feat_14\"]\n",
        "num_cols = [c for c in feature_cols if c not in cat_cols]\n",
        "print(f\"Num features: {len(num_cols)} | Cat features: {len(cat_cols)}\")\n",
        "\n",
        "train, test, cat_encoders = encode_categoricals(train, test, cat_cols)"
      ],
      "metadata": {
        "id": "LmGRHyPX7RqH"
      },
      "id": "LmGRHyPX7RqH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nkr3vizc7Rsn"
      },
      "id": "Nkr3vizc7Rsn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LqB3vjz683QU"
      },
      "id": "LqB3vjz683QU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-7FCWS7e83S2"
      },
      "id": "-7FCWS7e83S2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M_hj0o3k83Vi"
      },
      "id": "M_hj0o3k83Vi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### train & submit"
      ],
      "metadata": {
        "id": "djnZ7Ruy830s"
      },
      "id": "djnZ7Ruy830s"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "print(\"모델 학습 실행\")\n",
        "model = train_model(\n",
        "    train_df=train,\n",
        "    num_cols=num_cols,\n",
        "    cat_cols=cat_cols,\n",
        "    seq_col=seq_col,\n",
        "    target_col=target_col,\n",
        "    batch_size=CFG['BATCH_SIZE'],\n",
        "    epochs=CFG['EPOCHS'],\n",
        "    lr=CFG['LEARNING_RATE'],\n",
        "    device=device\n",
        ")\n",
        "\n",
        "print(\"추론 시작\")\n",
        "test_dataset = ClickDataset(test, num_cols, cat_cols, seq_col, has_target=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False,\n",
        "                         collate_fn=collate_fn_infer, pin_memory=True)\n",
        "model.eval()\n",
        "outs = []\n",
        "with torch.no_grad():\n",
        "    for num_x, cat_x, seqs, lens in tqdm(test_loader, desc=\"[Inference]\"):\n",
        "        num_x, cat_x, seqs, lens = num_x.to(device), cat_x.to(device), seqs.to(device), lens.to(device)\n",
        "        outs.append(torch.sigmoid(model(num_x, cat_x, seqs, lens)).cpu())\n",
        "test_preds = torch.cat(outs).numpy()\n",
        "print(\"추론 완료\")\n",
        "\n",
        "submit = pd.read_csv('./sample_submission.csv')\n",
        "submit['clicked'] = test_preds\n",
        "submit.to_csv('./test.csv', index=False)\n",
        "print(\"제출 파일 저장 완료\")"
      ],
      "metadata": {
        "id": "hfk0Gkck7RwC"
      },
      "id": "hfk0Gkck7RwC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hhuEwbsm8666"
      },
      "id": "hhuEwbsm8666",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rxrnptNn869j"
      },
      "id": "rxrnptNn869j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sf-2ycFN87AT"
      },
      "id": "sf-2ycFN87AT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FfdFahrr87C8"
      },
      "id": "FfdFahrr87C8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j3h6okzt87Fz"
      },
      "id": "j3h6okzt87Fz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ALsi2prI87Iq"
      },
      "id": "ALsi2prI87Iq",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}